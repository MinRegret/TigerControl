{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "import tigercontrol\n",
    "from tigercontrol.methods.control import ControlMethod\n",
    "from jax import grad,jit\n",
    "import jax.random as random\n",
    "from tigercontrol.utils import generate_key\n",
    "import jax\n",
    "import scipy\n",
    "\n",
    "class GPC(ControlMethod):\n",
    "    \"\"\"\n",
    "    Description: Computes optimal set of actions using the Linear Quadratic Regulator\n",
    "    algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    compatibles = set([])\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, A, B, x, n, m, H, HH, K = None):\n",
    "        \"\"\"\n",
    "        Description: Initialize the dynamics of the model\n",
    "        Args:\n",
    "            A,B (float/numpy.ndarray): system dynamics\n",
    "            n (float/numpy.ndarray): dimension of the state\n",
    "            m (float/numpy.ndarray): dimension of the controls\n",
    "            H (postive int): history of the controller \n",
    "            HH history of the system \n",
    "            x (float/numpy.ndarray): current state\n",
    "            past_w (float/numpy.ndarray)  previous perturbations \n",
    "        \"\"\"\n",
    "        self.initialized = True\n",
    "        \n",
    "        def _update_past(self_past, x):\n",
    "            new_past = np.roll(self_past, self.n)\n",
    "            new_past = jax.ops.index_update(new_past, 0, x)\n",
    "            return new_past\n",
    "        self._update_past = jit(_update_past)\n",
    "\n",
    "        if(K is None):\n",
    "            # solve the ricatti equation \n",
    "            X = scipy.linalg.solve_continuous_are(A, B, np.identity(n), np.identity(m))\n",
    "            #compute LQR gain\n",
    "            self.K = np.linalg.inv(B.T @ X @ B + np.identity(m)) @ (B.T @ X @ A)\n",
    "        else:\n",
    "            self.K = K\n",
    "\n",
    "        self.x = np.zeros(n)        \n",
    "        self.u = np.zeros(m)\n",
    "        \n",
    "        self.n = n   ## dimension of  the state x \n",
    "        self.m = m   ## dimension of the control u\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.H = H   ## how many control matrices\n",
    "        self.HH = HH ## how many times to unfold the recursion\n",
    "\n",
    "        ## internal parmeters to the class \n",
    "        self.T = 1 ## keep track of iterations, for the learning rate\n",
    "        self.learning_rate = 1\n",
    "        self.M = random.normal(generate_key(), shape=(H, m, n)) ## CANNOT BE SET TO ZERO\n",
    "        self.S = [B for i in range(HH)]\n",
    "        for i in range(1, HH):\n",
    "            self.S[i] = (A + B @ self.K) @ self.S[i-1]\n",
    "        self.w_past = np.zeros((HH + H,n)) ## this are the previous perturbations, from most recent [0] to latest [HH-1]\n",
    "\n",
    "        self.is_online = True\n",
    "\n",
    "    def the_complicated_loss_function(self, M, w_past, S):\n",
    "        \"\"\"\n",
    "        This is the counterfactual loss function, we prefer not to differentiate it and use JAX \n",
    "        \"\"\"\n",
    "        final = np.zeros(self.n)\n",
    "        for i in range(self.HH):\n",
    "            #temp = np.zeros(self.m)\n",
    "            #for j in range(self.H):\n",
    "            #    temp = temp + np.dot( M[j] , w_past[i+j])\n",
    "            temp = np.tensordot(M, w_past[i:i+self.H], axes=([0,2],[0,1]))\n",
    "            final = final + S[i] @ temp\n",
    "        return np.sum(final ** 2)\n",
    "\n",
    "    def plan(self,x_new):\n",
    "        \"\"\"\n",
    "        Description: Updates internal parameters and then returns the estimated optimal action (only one)\n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            Estimated optimal action\n",
    "        \"\"\"\n",
    "\n",
    "        self.T +=1\n",
    "        self.learning_rate = 1 / np.sqrt(self.T + 1)\n",
    "\n",
    "        w_new = x_new - np.dot(self.A , self.x)  - np.dot(self.B , self.u)\n",
    "        self.w_past = self._update_past(self.w_past, w_new)\n",
    "        self.x = x_new\n",
    "\n",
    "        #self.u = np.zeros(self.m)\n",
    "        #for i in range(self.H):\n",
    "        #    self.u += np.dot(self.M[i] , self.w_past[i])\n",
    "        self.u = - self.K @ x_new + np.tensordot(self.M, self.w_past[:self.H], axes=([0,2],[0,1]))\n",
    "        \n",
    "        grad_fn = jit(grad(self.the_complicated_loss_function))  # compiled gradient evaluation function\n",
    "        \n",
    "        self.M = self.M - self.learning_rate * grad_fn(self.M, self.w_past, self.S)\n",
    "        \n",
    "        return self.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tigercontrol.utils.random import set_key\n",
    "set_key(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulag/anaconda3/lib/python3.6/site-packages/jax/numpy/linalg.py:58: UserWarning: numpy.linalg support is experimental and may cause silent failures or wrong outputs\n",
      "  warnings.warn(_EXPERIMENTAL_WARNING)\n"
     ]
    }
   ],
   "source": [
    "problem = tigercontrol.problem(\"LDS-v0\")\n",
    "x = problem.initialize(n = 1, m = 1, noise_magnitude = 0.3, noise_distribution = 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = GPC()\n",
    "method.initialize(A = problem.A, B = problem.B, x = x, n = 1, m = 1, H = 3, HH = 30, K = np.zeros((1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 18 16:38:13 2019\n",
      "[0.20083119]\n",
      "[0.3693685]\n",
      "[0.0526429]\n",
      "[-0.06397448]\n",
      "[0.02098359]\n",
      "[0.02807364]\n",
      "[0.02046058]\n",
      "[-0.00052501]\n",
      "[0.00111327]\n",
      "[-0.000693]\n",
      "Fri Oct 18 16:38:18 2019\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "for i in range(10):\n",
    "    print(method.plan(x))\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 18 16:34:53 2019\n",
      "[0.20083119]\n",
      "[0.3693685]\n",
      "[0.15104842]\n",
      "[-0.05962548]\n",
      "[-0.00827806]\n",
      "[0.00710458]\n",
      "[0.03647117]\n",
      "[-0.003102]\n",
      "[0.007906]\n",
      "[-0.02375939]\n",
      "Fri Oct 18 16:34:58 2019\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "for i in range(10):\n",
    "    print(method.plan(x))\n",
    "print(time.ctime())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
