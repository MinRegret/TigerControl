{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of BPC, GPC, and LQR on Linear Dynamical Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnhallman/mlcourse/mlenv/lib/python3.6/site-packages/jax/lib/xla_bridge.py:120: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "import jax.random as random\n",
    "import tigercontrol\n",
    "from tigercontrol.utils.random import set_key, generate_key\n",
    "from tigercontrol.environments import Environment\n",
    "from tigercontrol.controllers import Controller\n",
    "from jax import grad,jit\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from controllers.bpc import BPC\n",
    "from controllers.gpc import GPC\n",
    "from controllers.lqr import LQR\n",
    "\n",
    "from environments.lds import LDS\n",
    "\n",
    "n_runs = 1\n",
    "alg_name = ['BPC', 'GPC', 'LQR']\n",
    "color_code = {'BPC': 'blue', 'GPC': 'purple', 'LQR': 'red'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(title, data, scale = 'linear'):\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(15,4))\n",
    "    axs[0].set_yscale(scale)\n",
    "    sns.lineplot(x = 'Time', y = 'Instantaneous Cost', hue = 'Algorithm', \n",
    "                 data = data, ax = axs[0], ci = 'sd', palette = color_code,\n",
    "                err_style = 'band').set_title(title)\n",
    "    axs[1].set_yscale(scale)\n",
    "    sns.lineplot(x = 'Time', y = 'Average Cost', hue = 'Algorithm', \n",
    "                 data = data, ax = axs[1], ci = 'sd', palette = color_code).set_title(title)\n",
    "    \n",
    "def to_dataframe(alg, loss, avg_loss, start = 10):\n",
    "    global T\n",
    "    return pd.DataFrame(data = {'Algorithm': alg, 'Time': np.arange(start = start, stop = T, dtype=np.float32),\n",
    "                                'Instantaneous Cost': loss[start:], 'Average Cost': avg_loss[start:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regret(T, alg_name, model, x):\n",
    "    loss = onp.zeros(T)\n",
    "    avg_regret = onp.zeros(T)\n",
    "    c_t = 0 # cost of initial function is 0\n",
    "    for i in range(T):\n",
    "        u = model.get_action()\n",
    "        c_t = loss_fn(x, u)\n",
    "        x = problem.step(u)\n",
    "        model.update(c_t, x)\n",
    "        loss[i] = c_t\n",
    "        if(i):\n",
    "            avg_regret[i] = avg_regret[i-1] * i / (i+1) + c_t /(i+1)\n",
    "        else:\n",
    "            avg_regret[i] = c_t\n",
    "    data = to_dataframe(alg_name, loss, avg_regret)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the LDS system, the matrices A, B are generated randomly. The cost function used is c(x, u) = ||x||2 + ||u||2 . The baseline is designed with the pre-fixed matrix K set to 0. In all figures, we plot the averaged results for a fixed random system determined by A, B, for each setting, over 20 experiment runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_distribution = 'normal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) d = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1 # dimension of  the state x \n",
    "m = 1 # control dimension\n",
    "T = 200 # number of timesteps\n",
    "\n",
    "problem = LDS()\n",
    "\n",
    "Q = 0.3 * np.identity(n)\n",
    "R = 0.3 * np.identity(m)\n",
    "\n",
    "loss_fn = lambda x, u: np.sum(x.T @ Q @ x + u.T @ R @ u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H = 8\n",
    "delta = 0.5 * H **0.75 / T**0.25\n",
    "\n",
    "bpc = BPC()\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = 'normal', noise_magnitude = 0.5)\n",
    "    bpc.initialize(problem.A, problem.B, n, m, H, K, delta, x)\n",
    "\n",
    "    if(run == 0):\n",
    "        BPC_data = get_regret(T, 'BPC', bpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'BPC', bpc, x)\n",
    "        BPC_data = pd.concat([BPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPC' object has no attribute 'M_norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b406922dcb93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mGPC_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_regret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GPC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_regret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GPC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-13c5acec8ce2>\u001b[0m in \u001b[0;36mget_regret\u001b[0;34m(T, alg_name, model, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlcourse/senior_ml/tigercontrol/in-progress/controllers/gpc.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, c_t, x_new)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_past\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mcurr_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcurr_norm\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcurr_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GPC' object has no attribute 'M_norm'"
     ]
    }
   ],
   "source": [
    "K = np.zeros((m, n))\n",
    "H, HH = 8, 16\n",
    "\n",
    "gpc = GPC()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = 'normal', noise_magnitude = 0.5)\n",
    "    gpc.initialize(problem.A, problem.B, H, HH, K, x, loss_fn = loss_fn)\n",
    "    \n",
    "    if(run == 0):\n",
    "        GPC_data = get_regret(T, 'GPC', gpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'GPC', gpc, x)\n",
    "        GPC_data = pd.concat([GPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr = LQR()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = 'normal', noise_magnitude = 0.5)\n",
    "    lqr.initialize(problem.A, problem.B, n, m, x, Q, R)\n",
    "    \n",
    "    if(run == 0):\n",
    "        LQR_data = get_regret(T, 'LQR', lqr, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'LQR', lqr, x)\n",
    "        LQR_data = pd.concat([LQR_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([BPC_data, GPC_data, LQR_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('Sanity check: (a) d = 1', all_data)\n",
    "plt.savefig(\"sanity_check_a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) d = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 # dimension of  the state x \n",
    "m = 10 # control dimension\n",
    "T = 200 # number of timesteps\n",
    "\n",
    "problem = LDS()\n",
    "\n",
    "Q = 0.3 * np.identity(n)\n",
    "R = 0.3 * np.identity(m)\n",
    "\n",
    "loss_fn = lambda x, u: x.T @ Q @ x + u.T @ R @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H = 8\n",
    "delta = 0.5 * H **0.75 / T**0.25\n",
    "bpc = BPC()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = 'normal', noise_magnitude = 0.5)\n",
    "    bpc.initialize(problem.A, problem.B, n, m, H, K, delta, x)\n",
    "    \n",
    "    if(run == 0):\n",
    "        BPC_data = get_regret(T, 'BPC', bpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'BPC', bpc, x)\n",
    "        BPC_data = pd.concat([BPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H, HH = 8, 16\n",
    "gpc = GPC()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = 'normal', noise_magnitude = 0.5)\n",
    "    gpc.initialize(problem.A, problem.B, H, HH, K, x, loss_fn = loss_fn)\n",
    "    \n",
    "    if(run == 0):\n",
    "        GPC_data = get_regret(T, 'GPC', gpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'GPC', gpc, x)\n",
    "        GPC_data = pd.concat([GPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr = LQR()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = 'normal', noise_magnitude = 0.5)\n",
    "    lqr.initialize(problem.A, problem.B, n, m, x, Q, R)\n",
    "    \n",
    "    if(run == 0):\n",
    "        LQR_data = get_regret(T, 'LQR', lqr, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'LQR', lqr, x)\n",
    "        LQR_data = pd.concat([LQR_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([BPC_data, GPC_data, LQR_data])\n",
    "plot('Sanity check: (b) d = 10', all_data)\n",
    "plt.savefig(\"sanity_check_b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) d = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # dimension of  the state x \n",
    "m = 100 # control dimension\n",
    "T = 200 # number of timesteps\n",
    "\n",
    "problem = LDS()\n",
    "x = problem.initialize(n, m, noise_distribution = 'normal', noise_magnitude = 0.5)\n",
    "\n",
    "Q = 0.3 * np.identity(n)\n",
    "R = 0.3 * np.identity(m)\n",
    "\n",
    "loss_fn = lambda x, u: x.T @ Q @ x + u.T @ R @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H = 8\n",
    "delta = H **0.75 / T**0.25\n",
    "\n",
    "bpc = BPC()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = 'normal', noise_magnitude = 0.5)\n",
    "    bpc.initialize(problem.A, problem.B, n, m, H, K, delta, x)\n",
    "    \n",
    "    if(run == 0):\n",
    "        BPC_data = get_regret(T, 'BPC', bpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'BPC', bpc, x)\n",
    "        BPC_data = pd.concat([BPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H, HH = 8, 16\n",
    "\n",
    "gpc = GPC()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = 'normal', noise_magnitude = 0.5)\n",
    "    gpc.initialize(problem.A, problem.B, H, HH, K, x, loss_fn = loss_fn)\n",
    "    \n",
    "    if(run == 0):\n",
    "        GPC_data = get_regret(T, 'GPC', gpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'GPC', gpc, x)\n",
    "        GPC_data = pd.concat([GPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr = LQR()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = 'normal', noise_magnitude = 0.5)\n",
    "    lqr.initialize(problem.A, problem.B, n, m, x, Q, R)\n",
    "    \n",
    "    if(run == 0):\n",
    "        LQR_data = get_regret(T, 'LQR', lqr, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'LQR', lqr, x)\n",
    "        LQR_data = pd.concat([LQR_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([BPC_data, GPC_data, LQR_data])\n",
    "plot('Sanity check: (c) d = 100', all_data)\n",
    "plt.savefig(\"sanity_check_c.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlated noise experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Random Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first setting, the noise terms are $w_{t+1} ∼ N(w_t,0.03^2)$, and are then clipped to the range [−1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_magnitude = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_w(n, x, u, w, t):\n",
    "    next_w = w + noise_magnitude * random.normal(generate_key(), shape = (n,))\n",
    "    next_w = np.minimum(np.ones(n), next_w)\n",
    "    next_w = np.maximum(-np.ones(n), next_w)\n",
    "    return next_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PROBLEM ##\n",
    "n = 10 # dimension of  the state x \n",
    "m = 10 # control dimension\n",
    "T = 500\n",
    "\n",
    "problem = LDS()\n",
    "x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "\n",
    "Q = 0.3 * np.identity(n)\n",
    "R = 0.3 * np.identity(m)\n",
    "\n",
    "loss_fn = lambda x, u: x.T @ Q @ x + u.T @ R @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H = 8\n",
    "delta = 0.5 * H **0.75 / T**0.25\n",
    "\n",
    "bpc = BPC()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    bpc.initialize(problem.A, problem.B, n, m, H, K, delta, x)\n",
    "    \n",
    "    if(run == 0):\n",
    "        BPC_data = get_regret(T, 'BPC', bpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'BPC', bpc, x)\n",
    "        BPC_data = pd.concat([BPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H, HH = 8, 16\n",
    "\n",
    "gpc = GPC()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    gpc.initialize(problem.A, problem.B, H, HH, K, x, loss_fn = loss_fn)\n",
    "    \n",
    "    if(run == 0):\n",
    "        GPC_data = get_regret(T, 'GPC', gpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'GPC', gpc, x)\n",
    "        GPC_data = pd.concat([GPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr = LQR()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    lqr.initialize(problem.A, problem.B, n, m, x, Q, R)\n",
    "    \n",
    "    if(run == 0):\n",
    "        LQR_data = get_regret(T, 'LQR', lqr, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'LQR', lqr, x)\n",
    "        LQR_data = pd.concat([LQR_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([BPC_data, GPC_data, LQR_data])\n",
    "plot('Correlated Gaussian Random Walk', all_data)\n",
    "plt.savefig(\"corr_gauss_rw_quad.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10 # max value of x/u\n",
    "loss_fn = lambda x, u: (1/D) * (np.linalg.norm(x) + np.linalg.norm(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H = 8\n",
    "delta = 0.5 * H **0.75 / T**0.25\n",
    "\n",
    "bpc = BPC()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    bpc.initialize(problem.A, problem.B, n, m, H, K, delta, x)\n",
    "    \n",
    "    if(run == 0):\n",
    "        BPC_data = get_regret(T, 'BPC', bpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'BPC', bpc, x)\n",
    "        BPC_data = pd.concat([BPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H, HH = 8, 16\n",
    "\n",
    "gpc = GPC()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    gpc.initialize(problem.A, problem.B, H, HH, K, x, loss_fn = loss_fn)\n",
    "    \n",
    "    if(run == 0):\n",
    "        GPC_data = get_regret(T, 'GPC', gpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'GPC', gpc, x)\n",
    "        GPC_data = pd.concat([GPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr = LQR()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    lqr.initialize(problem.A, problem.B, n, m, x, Q, R)\n",
    "    \n",
    "    if(run == 0):\n",
    "        LQR_data = get_regret(T, 'LQR', lqr, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'LQR', lqr, x)\n",
    "        LQR_data = pd.concat([LQR_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([BPC_data, GPC_data, LQR_data])\n",
    "plot('Correlated Gaussian Random Walk', all_data)\n",
    "plt.savefig(\"corr_gauss_rw_hinge.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sine Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_magnitude = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_w(n, x, u, w, t):\n",
    "    return noise_magnitude * np.sin(np.arange(t, t+n)/(2*n*np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PROBLEM ##\n",
    "n = 10 # dimension of  the state x \n",
    "m = 10 # control dimension\n",
    "T = 500\n",
    "\n",
    "problem = LDS()\n",
    "\n",
    "Q = 0.3 * np.identity(n)\n",
    "R = 0.3 * np.identity(m)\n",
    "\n",
    "loss_fn = lambda x, u: x.T @ Q @ x + u.T @ R @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H = 8\n",
    "delta = H **0.75 / T**0.25\n",
    "\n",
    "bpc = BPC()\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    bpc.initialize(problem.A, problem.B, n, m, H, K, delta, x)\n",
    "    \n",
    "    if(run == 0):\n",
    "        BPC_data = get_regret(T, 'BPC', bpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'BPC', bpc, x)\n",
    "        BPC_data = pd.concat([BPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H, HH = 8, 16\n",
    "\n",
    "gpc = GPC()\n",
    "GPC_loss, GPC_avg_regret = onp.zeros(T), onp.zeros(T)\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    gpc.initialize(problem.A, problem.B, H, HH, K, x, loss_fn = loss_fn)\n",
    "    \n",
    "    if(run == 0):\n",
    "        GPC_data = get_regret(T, 'GPC', gpc, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'GPC', gpc, x)\n",
    "        GPC_data = pd.concat([GPC_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr = LQR()\n",
    "LQR_loss, LQR_avg_regret = onp.zeros(T), onp.zeros(T)\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    lqr.initialize(problem.A, problem.B, n, m, x, Q, R)\n",
    "    \n",
    "    if(run == 0):\n",
    "        LQR_data = get_regret(T, 'LQR', lqr, x)\n",
    "    else:\n",
    "        new_data = get_regret(T, 'LQR', lqr, x)\n",
    "        LQR_data = pd.concat([LQR_data, new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([BPC_data, GPC_data, LQR_data])\n",
    "plot('Sinosoidal Noise with Quadratic Loss', all_data)\n",
    "plt.savefig(\"sin_quad.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 500\n",
    "D = 10 # max value of x/u\n",
    "loss_fn = lambda x, u: (1/D) * (np.linalg.norm(x) + np.linalg.norm(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H = 8\n",
    "delta = H **0.75 / T**0.25\n",
    "\n",
    "bpc = BPC()\n",
    "BPC_loss, BPC_avg_regret = onp.zeros(T), onp.zeros(T)\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    bpc.initialize(problem.A, problem.B, n, m, H, K, delta, x)\n",
    "    \n",
    "    loss_temp, avg_regret_temp = get_regret(T, bpc, x)\n",
    "    BPC_loss, BPC_avg_regret = BPC_loss + (1/n_runs) * loss_temp, BPC_avg_regret + (1/n_runs) * avg_regret_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H, HH = 8, 16\n",
    "\n",
    "gpc = GPC()\n",
    "GPC_loss, GPC_avg_regret = onp.zeros(T), onp.zeros(T)\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    gpc.initialize(problem.A, problem.B, H, HH, K, x, loss_fn = loss_fn)\n",
    "    \n",
    "    loss_temp, avg_regret_temp = get_regret(T, gpc, x)\n",
    "    GPC_loss, GPC_avg_regret = GPC_loss + (1/n_runs) * loss_temp, GPC_avg_regret + (1/n_runs) * avg_regret_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr = LQR()\n",
    "LQR_loss, LQR_avg_regret = onp.zeros(T), onp.zeros(T)\n",
    "\n",
    "for run in range(n_runs):\n",
    "    set_key(run)\n",
    "    \n",
    "    x = problem.initialize(n, m, noise_distribution = get_next_w)\n",
    "    lqr.initialize(problem.A, problem.B, n, m, x)\n",
    "    \n",
    "    loss_temp, avg_regret_temp = get_regret(T, lqr, x)\n",
    "    LQR_loss, LQR_avg_regret = LQR_loss + (1/n_runs) * loss_temp, LQR_avg_regret + (1/n_runs) * avg_regret_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = T - 10\n",
    "all_data = pd.concat([to_dataframe('BPC', BPC_loss[10:], BPC_avg_regret[10:]), \n",
    "                      to_dataframe('GPC', GPC_loss[10:], GPC_avg_regret[10:]),\n",
    "                      to_dataframe('LQR', LQR_loss[10:], LQR_avg_regret[10:])])\n",
    "\n",
    "plot('Sinosoidal Noise with Hinge Loss', all_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
