{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "import jax.random as random\n",
    "import tigercontrol\n",
    "from tigercontrol.utils.random import set_key\n",
    "from tigercontrol.environments import Environment\n",
    "from tigercontrol.controllers import Controller\n",
    "from jax import grad,jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_key(0) # make everything deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Linear dynamical system\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class LDS(Environment):\n",
    "    \"\"\"\n",
    "    Description: The base, master LDS class that all other LDS subenvironments inherit. \n",
    "        Simulates a linear dynamical system with a lot of flexibility and variety in\n",
    "        terms of hyperparameter choices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, n, m, noise_distribution=None, noise_magnitude=1.0, A = None, B = None, initial_state = None):\n",
    "        \"\"\"\n",
    "        Description: Randomly initialize the hidden dynamics of the system.\n",
    "        Args:\n",
    "            n (int): State dimension.\n",
    "            m (int): control dimension.\n",
    "            noise_distribution (None, string, func): if None then no noise. Valid strings include ['normal', 'uniform']. \n",
    "                Valid noise functions must map inputs n (x dim), x (state), u (action), w (previous noise), and t (current time)\n",
    "                to either a scalar or an n-dimensional vector of real values.\n",
    "            noise magnitude (float): magnitude of noise\n",
    "            params (dict): specify A, B\n",
    "            initial_state (None, vector): initial x. If None then randomly initialized\n",
    "        Returns:\n",
    "            The first value in the time-series\n",
    "        \"\"\"\n",
    "        self.initialized = True\n",
    "        self.T = 0\n",
    "        self.n, self.m = n, m\n",
    "        self.noise_magnitude = noise_magnitude\n",
    "\n",
    "        # random normal helper function\n",
    "        gaussian = lambda dims: random.normal(generate_key(), shape=dims)\n",
    "        \n",
    "        self.A = gaussian((n, n))\n",
    "        self.B = gaussian((n, m))\n",
    "        \n",
    "        #self.A /= np.linalg.norm(self.A, ord=2)\n",
    "        #self.B /= np.linalg.norm(self.B, ord=2)\n",
    "\n",
    "        # determine the noise function to use, allowing for conditioning on x, u, previous noise, and current t\n",
    "        if (noise_distribution == None):           # case no noise\n",
    "            self.noise = lambda n, x, u, w, t: 0.0\n",
    "        elif (noise_distribution == 'normal'):   # case normal distribution\n",
    "            self.noise = lambda n, x, u, w, t: gaussian((n,))\n",
    "        elif (noise_distribution == 'uniform'): # case uniform distribution\n",
    "            self.noise = lambda n, x, u, w, t: random.uniform(generate_key(), shape=(n,), minval=-1, maxval=1)\n",
    "        else:                                      # case custom function\n",
    "            assert callable(noise_distribution), \"noise_distribution not valid input\" # assert input is callable\n",
    "            from inspect import getargspec\n",
    "            arg_sub = getargspec(noise_distribution).args # retrieve all parameters taken by provided function\n",
    "            for arg in arg_sub:\n",
    "                assert arg in ['n', 'x', 'u', 'w', 't'], \"noise_distribution takes invalid input\"\n",
    "            def noise(n, x, u, w, t):\n",
    "                noise_args = {'n': n, 'x': x, 'u': u, 'w': w, 't': t}\n",
    "                arg_dict = {k:v for k,v in noise_args.items() if k in arg_sub}\n",
    "                return noise_distribution(**arg_dict)\n",
    "            self.noise = noise\n",
    "\n",
    "        # initial state\n",
    "        #self.x = np.zeros(n) if initial_state is None else initial_state\n",
    "        self.x = gaussian((n,)) if initial_state is None else initial_state\n",
    "        \n",
    "        def _step(x, u, eps):\n",
    "            eps_x = eps\n",
    "            next_x = np.dot(self.A, x) + np.dot(self.B, u) + self.noise_magnitude * eps_x\n",
    "            return (next_x, next_x)\n",
    "        self._step = jax.jit(_step)\n",
    "\n",
    "        self.prev_noise = np.zeros(n)\n",
    "        return self.x # return true current state\n",
    "\n",
    "\n",
    "    def step(self, u):\n",
    "        \"\"\"\n",
    "        Description: Moves the system dynamics one time-step forward.\n",
    "        Args:\n",
    "            u (numpy.ndarray): control input, an n-dimensional real-valued vector.\n",
    "        Returns:\n",
    "            A new observation from the LDS.\n",
    "        \"\"\"\n",
    "        assert self.initialized\n",
    "        self.T += 1\n",
    "        self.prev_noise = self.noise(self.n, self.x, u, self.prev_noise, self.T)\n",
    "        self.x, y = self._step(self.x, u, self.prev_noise)\n",
    "        return y # even in fully observable case, y = self.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # dimension of  the state x \n",
    "m = 5 # control dimension\n",
    "problem = LDS()\n",
    "x = problem.initialize(n, m, noise_magnitude = 0.2)\n",
    "Q = np.identity(n)\n",
    "R = np.identity(m)\n",
    "loss_fn = lambda x, u: x.T @ Q @ x + u.T @ R @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditGPC(Controller):\n",
    "    \"\"\"\n",
    "    Description: Computes optimal set of actions using the Linear Quadratic Regulator\n",
    "    algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, A, B, n, m, H, K):\n",
    "        \"\"\"\n",
    "        Description: Initialize the dynamics of the model\n",
    "        Args:\n",
    "            A,B (float/numpy.ndarray): system dynamics\n",
    "            K  (float/numpy.ndarray): optimal controller \n",
    "            n (float/numpy.ndarray): dimension of the state\n",
    "            m (float/numpy.ndarray): dimension of the controls\n",
    "            H (postive int): history of the controller \n",
    "        \"\"\"\n",
    "        self.initialized = True\n",
    "        \n",
    "        def _update_past(self_past, x):\n",
    "            new_past = np.roll(self_past, 1)\n",
    "            new_past = jax.ops.index_update(new_past, 0, x)\n",
    "            return new_past\n",
    "        self._update_past = jit(_update_past)\n",
    "        \n",
    "        self.K = np.zeros ((m,n)) ## compute it...\n",
    "\n",
    "        self.x = np.zeros(n)        \n",
    "        self.u = np.zeros(m)\n",
    "        \n",
    "        self.n = n   ## dimension of  the state x \n",
    "        self.m = m   ## dimension of the control u\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.H = H   ## how many control matrices\n",
    "\n",
    "        ## internal parmeters to the class \n",
    "        self.T = 1 ## keep track of iterations, for the learning rate\n",
    "        self.learning_rate = 1\n",
    "        self.M = np.ones((H, m, n)) ## CANNOT BE SET TO ZERO\n",
    "        self.w_past = np.zeros((H,n)) ## this are the previous perturbations, from most recent [0] to latest [HH-1]\n",
    "\n",
    "    def plan(self, c_t, x_new):\n",
    "        \"\"\"\n",
    "        Description: Updates internal parameters and then returns the estimated optimal action (only one)\n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            Estimated optimal action\n",
    "        \"\"\"\n",
    "\n",
    "        self.T += 1\n",
    "        self.learning_rate = 1 / np.sqrt(self.T + 1) # NEED DIFF LEARNING RATE\n",
    "\n",
    "        w_new = x_new - np.dot(self.A , self.x)  - np.dot(self.B , self.u)\n",
    "        self.w_past = self._update_past(self.w_past, w_new)\n",
    "        self.x = x_new\n",
    "\n",
    "        self.u = np.zeros(self.m)\n",
    "        for i in range(self.H):\n",
    "            self.u += np.dot(self.M[i] , self.w_past[i])\n",
    "            \n",
    "        #g_t = (self.d * self.H / delta_t) * loss_t * np.sum(self.u, axis=0)\n",
    "        #lr = self.initial_lr / self.t**0.75 # eta_t = O(t^(-3/4))\n",
    "        self.M = self.M - self.learning_rate * c_t # need epsilons\n",
    "        \n",
    "        return self.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.zeros((m, n))\n",
    "H, HH = 3, 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 30\n",
    "model = BanditGPC()\n",
    "model.initialize(problem.A, problem.B, n, m, H, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPC_results = []\n",
    "c_t = 0 # cost of initial function is 0\n",
    "for i in range(T):\n",
    "    print(x)\n",
    "    u = model.plan(c_t, x)\n",
    "    c_t = loss_fn(x, u)\n",
    "    x = problem.step(u)\n",
    "    GPC_results.append(c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = problem.initialize(n, m, d, noise = 0.2)\n",
    "\n",
    "X = scipy.linalg.solve_discrete_are(problem.A, problem.B, Q, R)\n",
    "K = np.linalg.inv(B.T @ X @ B + R) @ (B.T @ X @ A)\n",
    "\n",
    "LQR_results = []\n",
    "for i in range(T):\n",
    "    u = -K @ x\n",
    "    x = problem.step(u)\n",
    "    LQR_results.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([np.linalg.norm(i) for i in GPC_results], label = \"GPC\")\n",
    "plt.plot([np.linalg.norm(i) for i in LQR_results], label = \"LQR\")\n",
    "plt.title(\"GPC vs. LQR on LDS\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LQR first to get good initial K estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPC()\n",
    "model.initialize(problem.A, problem.B, x, n, m, 3, 30, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
